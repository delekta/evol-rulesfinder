Steps of my work:
- 1. run rulesfinder.py with --hashcat
- 2. you get file of rules in results directory 
- 3. then we have main.py we run our evolutionary algo, to mangle our rules
- 4. then we get evol_algo_result.txt
- 5. then we can go with hashcat_attack.py
- 6. then we john_attack.py

Can we find the input and outputs of whole flow?

Lets automate it 

If you make something interesting, the 4. chapter will be easy. Note future improvements

Check if all of it works and push it. 

Always first hour of the day.

First results:

11 June 2024 - 2049/61682 (3.32%) vs after rulesfinder (30.40%)

Pomysły na opisy:
- Opisz proces. Ze no są gorsze wyniki niz z rulesfindera ale zaczales bardzo slabo i pozniej poprawiales i ma to sens na przyszlosc.
- Proces jak zapisuje wszystko w poszczególnych ze cos w ./hashcat_log.txt itp
- Czy powinienem porównywać z tymi samymi cleartext i wordlist co podaje do rulesfindera
- [usniecie mutation] nie duzo zmienia w sumie nic
- [worst population] has better results probably becuase shorter rules są wybierane. Bo źle to liczę. Ja sumuje czyli dłusze rule są promowane. A dluzsze nie sa tak dobre
- [sprawdz popular + short] to premiuj i zobacz wyniki


Następny ticket jest zeby zaautmatyzować do jednej komendy sprawdzającej. Która wykona parę komend tych wszystkich co trzeba. 

[test] popularity sum + mutation 
[without mutation] popularity sum - mutation
[choose worst popularity] worst popularity - mutation 
Wnioski: to jest efektywne tylko dlatego ze mamy złą metode do liczenie popularity. Jedynie czemu to dziala to dlatego ze sumowanie i jak wybieramy worst to premiuje małe reguły
Więć spróbujmy napiać takie coś co premiuje małe reguły i lepsze reguły.

Pytanie jak bardzo premiować krótkie frazy. Lets test it
[popularity + 600 - 100*len] No trochę lepiej niz test, ale tylko ciupk

Dwa rozdziały:
1. Manipuluje popularity function
2. Manipuluje argumentami to algorytmu ewolucyjnego

TODO napisz w magisterece jak powstał słownik najlepszych reguł


